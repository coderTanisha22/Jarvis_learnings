{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderTanisha22/Jarvis_learnings/blob/main/Copy_of_hugging_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "496sFhO9r0Ow"
      },
      "outputs": [],
      "source": [
        "!pip install transformers #pretrained AI models access\n",
        "!pip install torch #pytorch backened use to run models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwHPMwlms9ef"
      },
      "outputs": [],
      "source": [
        "!pip install gradio transformers torch #for maing a new web interface for chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdhAejpJsIoj"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZKjwsd1w_4e"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "chatbot_model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCg334T4tWPV"
      },
      "outputs": [],
      "source": [
        "chathis_tokens = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMkaMbGcyOc8"
      },
      "outputs": [],
      "source": [
        "def generate_response(messages, chatbot=None):\n",
        "    global chathis_tokens\n",
        "    try:\n",
        "        if isinstance(messages, str):\n",
        "            messages = [{\"role\": \"user\", \"content\": messages}]\n",
        "\n",
        "        user_message = messages[-1][\"content\"]\n",
        "\n",
        "        user_tokens = tokenizer.encode(user_message + tokenizer.eos_token, return_tensors='pt')\n",
        "        model_input = torch.cat([chathis_tokens, user_tokens], dim=-1) if chathis_tokens is not None else user_tokens\n",
        "\n",
        "        response_tokens = chatbot_model.generate(\n",
        "            model_input,\n",
        "            max_length=1000,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        new_tokens = response_tokens[0][model_input.shape[-1]:]\n",
        "        bot_reply = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
        "        messages.append({\"role\": \"assistant\", \"content\": bot_reply})\n",
        "        chathis_tokens = response_tokens\n",
        "\n",
        "        return messages\n",
        "\n",
        "    except Exception as e:\n",
        "        if not isinstance(messages, list):\n",
        "            messages = [{\"role\": \"user\", \"content\": str(messages)}]\n",
        "        messages.append({\"role\": \"assistant\", \"content\": f\"[Error] {str(e)}\"})\n",
        "        return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "438RtTZQyqBi"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "gr.ChatInterface(fn=generate_response, type=\"messages\").launch(debug=True) #so that it shows the error messege; it's not hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EW3qLrL-ajO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGdsFrbZzi5odxbAypMqQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}