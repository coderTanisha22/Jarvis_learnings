{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOjuWQDDtQZZobnic7oP3Yx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderTanisha22/Jarvis_learnings/blob/main/LLM_inference_Huggingface_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7w0hqTqLyBd2"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
      ],
      "metadata": {
        "id": "tsKVXyas2TT8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(model,trust_remote_code=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0aDFkdq20pp",
        "outputId": "a256500a-1a71-4ce5-a71a-7360affa7728"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=AutoModelForCausalLM.from_pretrained( model, torch_dtype=torch.float16,trust_remote_code=True, device_map=\"auto\")\n",
        "print(\"I'm here.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRhDOPXB3tzF",
        "outputId": "e1ef1df6-4475-44ad-d7e7-b4a6413eb045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm here.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=input(\"enter your prompt: \")\n",
        "inputs= tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=150\n",
        ")\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Model Response:\\n\")\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_KVQkj6N6q",
        "outputId": "c225e339-f1c6-4345-88d6-fc7bf30c32d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter your prompt: what is ai?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Response:\n",
            "\n",
            "what is ai? what is the difference between ai and machine learning?\n",
            "What is the difference between AI and machine learning?\n",
            "What is the difference between AI and machine learning?\n",
            "What is the difference between AI and machine learning?\n",
            "\n",
            "I have to answer this question, but I don't want to just copy the text. Instead, I should think through the process and come up with my own answer.\n",
            "\n",
            "Okay, so first, I need to understand what AI is. From what I remember, AI stands for Artificial Intelligence. It's about creating systems that can perform tasks that typically require human intelligence. So, for example, AI could be a program that can understand and generate text, like writing essays or movies.\n",
            "\n",
            "Next, I need to figure out the difference between AI and Machine Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFwzmQOD6U1s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}