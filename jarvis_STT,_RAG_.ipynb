{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM6GDxNIwXDgF3DDH7eb0Fi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderTanisha22/Jarvis_learnings/blob/main/jarvis_STT%2C_RAG_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPUs are preffered for\n",
        "1. Speech Recognition (Voice input)\tHeavy models, real-time audio\n",
        "\n",
        "\twhisper, whisper-large\n",
        "2. Large Language Models (LLMs)\tNeed fast inference + more memory\n",
        "llama, mistral, phi-2\n",
        "3. Document summarization\tLong context input, Transformer-heavy\n",
        "\n",
        "\tbart-large-cnn, t5-xxl\n",
        "4. Image understanding (OCR/Vision)\tVision transformers can be large\n",
        "\n",
        "\tCLIP, Donut, BLIP\n",
        "5. Real-time multimodal Jarvis\tVoice + Text + Image combo\n",
        "Whisper + GPT + TTS\n",
        "\n",
        "Disadvanntage of using colab\n",
        "Everyting is lost when session expires, the installed packages, variables etc."
      ],
      "metadata": {
        "id": "Z4U99GAorig2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2\", device=0)  # 0 = use first GPU\n",
        "sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "sentiment(\"I love Jarvis!\")"
      ],
      "metadata": {
        "id": "wyZTQcNooP3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment(\"I love Jarvis!\")"
      ],
      "metadata": {
        "id": "Zn_PaSDToWyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe(\"I love coding\")"
      ],
      "metadata": {
        "id": "Vzw2hiFIpjzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import pipeline\n",
        "#translating english to french\n",
        "translator = pipeline(\"translation_en_to_fr\", model=\"t5-base\")\n",
        "translator(\"Hello, how are you?\")"
      ],
      "metadata": {
        "id": "Ue8hD2PVpnvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "twNGenbLR8lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Use the uploaded file name exactly\n",
        "audio = AudioSegment.from_file(\"er voice 2.m4a\")\n",
        "audio.export(\"audio.wav\", format=\"wav\")\n"
      ],
      "metadata": {
        "id": "qZ8eAQ4QUrH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "converting speech to text LLM"
      ],
      "metadata": {
        "id": "pQSjQz2-gsGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting speech to text\n",
        "#from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-small\",\n",
        "    return_timestamps=True\n",
        ")\n",
        "\n",
        "result = pipe(\"audio.wav\")\n",
        "print(result['text'])"
      ],
      "metadata": {
        "id": "rPWVR_AgVDlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q/A LLM"
      ],
      "metadata": {
        "id": "ZhsMB5ulgzEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n"
      ],
      "metadata": {
        "id": "p1CjFNIuVF7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"\"\"\n",
        "India is the world's largest democracy. It is located in South Asia and is bordered by Pakistan, China, Nepal, Bhutan, Bangladesh, and Myanmar.\n",
        "It has a population of over 1.4 billion people and a parliamentary system of government.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "cytqRCzff89S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Which countries border India?\"\n",
        "result = qa(question=question, context=context)\n",
        "print(\"Answer:\", result['answer'])\n"
      ],
      "metadata": {
        "id": "hbJMebPigAzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques = \"Population of India?\"\n",
        "result = qa(question=ques, context=context)\n",
        "print(\"Answer:\", result['answer'])"
      ],
      "metadata": {
        "id": "and-z_oAgBbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Generation LLMs"
      ],
      "metadata": {
        "id": "2eTWi4esgYZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_id = \"Salesforce/codegen-350M-multi\" #model name, codegen for supporting multiple programming language\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "prompt = \"\"\"Write a standalone Python function that prints factorial of n.\"\"\"\n",
        "\n",
        "#tokenizing the prompt and returning to pytorch\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate code\n",
        "outputs = model.generate(\n",
        "    inputs.input_ids, #generating the tokens of input taken\n",
        "    max_length=200,  #maximum length of output, else it may run slow\n",
        "    num_return_sequences=1,  #to get single or variations of code\n",
        "    do_sample=True, #we do this for random, creative code generation (not only greedy)\n",
        "    temperature=0.7, #randomness level, 0.7 is balanced\n",
        ")\n",
        "\n",
        "# Decode the tokens\n",
        "generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "#output[0] refers to the first set of generated output, here we have generated only one output\n",
        "#skip for skipping some special tokens which are added during the conversion like <pad> , <s>, </s>\n",
        "print(generated_code)\n"
      ],
      "metadata": {
        "id": "3uGSEX2-gT4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Working on RAG"
      ],
      "metadata": {
        "id": "7bBHSQ4ht-lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "tHFs3UPDhQIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "p2LuxNF-yjP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3"
      ],
      "metadata": {
        "id": "VqLeYP5pkfri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3\n",
        "\n",
        "def speak_text(text):\n",
        "    engine = pyttsx3.init()\n",
        "    engine.say(text)\n",
        "    engine.runAndWait()"
      ],
      "metadata": {
        "id": "m6xEWY0RkSWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading models\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')  # fast & good\n",
        "gpt2 = pipeline(\"text-generation\", model=\"gpt2-medium\")"
      ],
      "metadata": {
        "id": "caEyPX-EzHID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\n",
        "    \"Artificial Intelligence is the simulation of human intelligence in machines.\",\n",
        "    \"Python is a high-level, interpreted programming language.\",\n",
        "    \"The Earth revolves around the Sun in an elliptical orbit.\",\n",
        "    \"Jarvis is a personal assistant AI system inspired by Iron Man.\"\n",
        "]\n",
        "doc_embeddings = embedder.encode(docs)"
      ],
      "metadata": {
        "id": "tZePBrru0sLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dim = doc_embeddings.shape[1]  #tells the embedding size(no. of columns)\n",
        "index = faiss.IndexFlatL2(dim)\n",
        "index.add(np.array(doc_embeddings))"
      ],
      "metadata": {
        "id": "zomSM7Vp0xm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relevant_doc(query):\n",
        "    query_embedding = embedder.encode([query])\n",
        "    D, I = index.search(np.array(query_embedding), k=1) #D is the distance/similarity score, I is the index of the closest document\n",
        "    return docs[I[0][0]]"
      ],
      "metadata": {
        "id": "HJ7iV0VT3zTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to find relevant documents based on user query\n",
        "def generate_with_context(query):\n",
        "    context = get_relevant_doc(query)\n",
        "    prompt = f\"Context: {context}\\nQuestion: {query}\\nAnswer:\"\n",
        "    output = gpt2(prompt, max_new_tokens=50, truncation=True, pad_token_id=50256)\n",
        "    return output[0]['generated_text'] #returns the final generated text"
      ],
      "metadata": {
        "id": "P9q1c7NOy5__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "pzE4YsmkxHqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ gTTS for Text-to-Speech\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "import os\n",
        "\n",
        "def speak_text(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save(\"jarvis_output.mp3\")\n",
        "    display(Audio(\"jarvis_output.mp3\", autoplay=True))"
      ],
      "metadata": {
        "id": "dkfComr1u8Hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"🎤 Type your question for Jarvis: \")\n",
        "response = generate_with_context(query)\n",
        "print(\"Jarvis says:\", response)\n",
        "speak_text(response)"
      ],
      "metadata": {
        "id": "WKmktDCiy9LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LpydPpQKzQz4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}